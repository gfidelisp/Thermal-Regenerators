{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15cb112",
   "metadata": {},
   "source": [
    "# Deep Learning in Active Magnetic Regenerators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c8227",
   "metadata": {},
   "source": [
    "This Notebook presents the results for the application of Neural Networks in the prediction of the Cooling Capacity ($\\dot{Q}_\\mathrm{C}$ or $Qc$) and the Magnetization Power ($\\dot{W}_\\mathrm{m}$ or $Wm$) of Active Magnetic Regenerators. The Dataset consists in 532 points coming from numerical simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f599ee",
   "metadata": {},
   "source": [
    "### Importing the Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c66d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import joblib\n",
    "\n",
    "mpl.style.use('default')\n",
    "plt.rc('text',usetex = True)\n",
    "plt.rc('font', family='serif',size = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135a2df",
   "metadata": {},
   "source": [
    "### Plotting Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea8caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(y_train,y_pred_train,y_test,y_pred_test,Obj):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(y_train,y_pred_train,'o',color = '#1f77b4', mfc='none', label = 'Training Set')\n",
    "    plt.plot(y_test,y_pred_test,'x' ,color = '#2ca02c', mfc='none',label = 'Test Set',)\n",
    "    \n",
    "    if Obj == 'Qc':\n",
    "        Aux = np.linspace(10,300)\n",
    "        plt.plot(Aux,0.9*Aux,'k--')\n",
    "        plt.plot(Aux,1.1*Aux,'k--')\n",
    "        plt.text(140, 180, '$+ 10 \\%$', fontsize=12)\n",
    "        plt.text(150, 120, '$- 10 \\%$', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.ylabel(r' $\\dot{Q}_\\mathrm{C}$ [W] - NN' )\n",
    "        plt.xlabel(r' $\\dot{Q}_\\mathrm{C}$ [W] - Target')\n",
    "        plt.grid(linestyle='dotted')\n",
    "        plt.savefig('Plots/Qc/Qc - NN.png', format = 'png', bbox_inches='tight') \n",
    "    \n",
    "    elif Obj == 'Wm':\n",
    "        Aux = np.linspace(10,60)\n",
    "        plt.plot(Aux,0.9*Aux,'k--')\n",
    "        plt.plot(Aux,1.1*Aux,'k--')\n",
    "        plt.text(23, 17, '$- 10 \\%$', fontsize=12)\n",
    "        plt.text(19, 28, '$+ 10 \\%$', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.ylabel(r' $\\dot{W}_\\mathrm{AMR,Mag}$ [W] - NN' )\n",
    "        plt.xlabel(r' $\\dot{W}_\\mathrm{AMR,Mag}$ [W] - Target')\n",
    "        plt.grid(linestyle='dotted')\n",
    "        plt.savefig('Plots/Wm/Wm - NN.png', format = 'png', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfad5c8",
   "metadata": {},
   "source": [
    "### Reading the Input Parameteres "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7afc02",
   "metadata": {},
   "source": [
    "The independent variable are the Width ($H$), Height ($H$) and Length ($L$) of the porous medium, the frequency ($f$) and mass flow rate ($mf$) of the Active Magnetic Regenerator, the Inlet Temperatures at the Hot ($Th$) and Cold ($Tc$) ends and the Applied Magnetic Field ($B$).\n",
    "\n",
    "The dependent variables are the Cooling Capacity ($Qc$) and Magnetization Power ($Wm$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433b6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inputs = pd.read_excel('Data/Data_AMR.xlsx',index_col = 0, dtype=np.float32) # Input Data\n",
    "X = Inputs[['W','H','f','mf','B','L','Th','Tc']]\n",
    "y = Inputs[['Qc','Wm']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66827bab",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd528a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f012151",
   "metadata": {},
   "source": [
    "### Scaling the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f363b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(X_train)\n",
    "x_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae7985",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7349548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build(hp):\n",
    "    \n",
    "    #Grouping a stack of Layers in Model\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Adding the Layers\n",
    "    # The number of layers, neurons in each one and activation functions are going to be tunned \n",
    "    for i in range(hp.Int('layers', 0, 10)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i), 10, 10100, step=250),\n",
    "                                        activation=hp.Choice('act_' + str(i), ['relu','sigmoid','selu'])))\n",
    "        \n",
    "        #Applying a Batch Normalization Layer after Dense Layer\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "    # Adding a final Layer \n",
    "    model.add(tf.keras.layers.Dense(1, activation='selu'))\n",
    "    \n",
    "    # Compiling the Model with the Adam optimization algorithm\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=\"mean_squared_error\", \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8323d781",
   "metadata": {},
   "source": [
    "### Batch Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35377ce",
   "metadata": {},
   "source": [
    "Overriding run_trial in MyTuner (https://kegui.medium.com/how-to-tune-the-number-of-epochs-and-batch-size-in-keras-tuner-c2ab2d40878d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c468b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.Hyperband):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 20, 200, step=10)\n",
    "        super(MyTuner, self).run_trial(trial, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd89db08",
   "metadata": {},
   "source": [
    "### Defining the Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b763ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuNet(X_train,y_train,max_epochs,Obj):\n",
    "    \n",
    "    # Defining the Tuner\n",
    "    tuner = MyTuner(Build,\n",
    "                    objective = 'val_loss',\n",
    "                    max_epochs = max_epochs,\n",
    "                    directory='KT_Dir',\n",
    "                    project_name='KT_Hyperband_' + Obj,\n",
    "                    executions_per_trial = 1,   \n",
    "    )\n",
    "    \n",
    "    # Hyperparameter Optimization\n",
    "    tuner.search(X_train,\n",
    "                 y_train[Obj],\n",
    "                 epochs=max_epochs,\n",
    "                 callbacks=[EarlyStopping('val_loss', patience=3)],\n",
    "                 verbose=1,\n",
    "                 validation_split=0.2)\n",
    "    \n",
    "  \n",
    "    # Trainning the Best Model\n",
    "    best_model = tuner.get_best_models()[0]\n",
    "    best_model.build(x_train.shape)\n",
    "    best_model.fit(x_train,\n",
    "                   y_train[Obj], \n",
    "                   epochs=max_epochs,\n",
    "                   batch_size=tuner.get_best_hyperparameters(num_trials=1)[0].get('batch_size')\n",
    "    )\n",
    "    \n",
    "    # Saving the Model\n",
    "    best_model.save('Models/'+Obj+'/'+ Obj +'_NN.h5')\n",
    "    \n",
    "     #R2 for the Training Set\n",
    "    print('The coefficient of determination for '+ Obj +' Training Set using Neural Networks is '+\n",
    "          str(r2_score(y_train[Obj], best_model.predict(X_train))))\n",
    "\n",
    "    # R2 for the Test Set\n",
    "    print('The coefficient of determination for '+ Obj +' Test Set using Neural Networks is '+\n",
    "          str(r2_score(y_test[Obj], best_model.predict(X_test)))) \n",
    "\n",
    "    # Plotting the Results\n",
    "    plot_results(y_train[Obj], best_model.predict(X_train), y_test[Obj], best_model.predict(X_test), Obj) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc4f4334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project KT_Dir\\KT_Hyperband_Qc\\oracle.json\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "layers            |6                 |?                 \n",
      "tuner/epochs      |3                 |?                 \n",
      "tuner/initial_e...|0                 |?                 \n",
      "tuner/bracket     |4                 |?                 \n",
      "tuner/round       |0                 |?                 \n",
      "\n",
      "Epoch 1/3\n",
      "17/17 [==============================] - 3s 59ms/step - loss: 27363.7227 - accuracy: 0.0000e+00 - val_loss: 28079.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 27239.6230 - accuracy: 0.0000e+00 - val_loss: 28090.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "17/17 [==============================] - 0s 16ms/step - loss: 27117.1289 - accuracy: 0.0000e+00 - val_loss: 28077.2383 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilh\\AppData\\Local\\Temp/ipykernel_12376/3484108109.py:13: DeprecationWarning: `Tuner.run_trial()` returned None. It should return one of float, dict, keras.callbacks.History, or a list of one of these types. The use case of calling `Tuner.oracle.update_trial()` in `Tuner.run_trial()` is deprecated, and will be removed in the future.\n",
      "  tuner.search(X_train,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown metric: val_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12376/1615130697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNeuNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Qc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12376/3484108109.py\u001b[0m in \u001b[0;36mNeuNet\u001b[1;34m(X_train, y_train, max_epochs, Obj)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Hyperparameter Optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     tuner.search(X_train,\n\u001b[0m\u001b[0;32m     14\u001b[0m                  \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mObj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                  \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m                     ),\n\u001b[0;32m    197\u001b[0m                 )\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreport_trial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# Display needs the updated trial scored by the Oracle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[1;34m(self, trial_id, status)\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrial_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mscore_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \"\"\"\n\u001b[0;32m    160\u001b[0m         \u001b[1;31m# Assumes single objective, subclasses can override.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\metrics_tracking.py\u001b[0m in \u001b[0;36mget_best_value\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_best_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\engine\\metrics_tracking.py\u001b[0m in \u001b[0;36m_assert_exists\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_assert_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown metric: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown metric: val_loss"
     ]
    }
   ],
   "source": [
    "NeuNet(X_train,y_train,200,'Qc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6150e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
